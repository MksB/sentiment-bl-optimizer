{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR6FjHA0r19P"
   },
   "source": [
    "# A Computational Implementation of the Black-Litterman Model: Mathematical Foundations and Practical Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_35swuhsZcA"
   },
   "source": [
    "The Black-Litterman Model Examples: Demonstrates various use cases and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDZBnbzMcmuB",
    "outputId": "c5213f79-6bd0-41b2-bc08-9e1a3d30ab05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in /usr/local/lib/python3.12/dist-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBdvH9sgskkw",
    "outputId": "f5a003dc-3c3e-4e3e-911d-4959f6ee7949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 1: Basic Black-Litterman Usage\n",
      "================================================================================\n",
      "\n",
      "Prior Expected Returns:\n",
      "  Stocks         :   8.00%\n",
      "  Bonds          :   4.00%\n",
      "  Gold           :   5.00%\n",
      "  Real Estate    :   6.00%\n",
      "\n",
      "Views:\n",
      "  1. Stocks will return 10.0%\n",
      "  2. Bonds will outperform Gold by 2.0%\n",
      "\n",
      "Posterior Returns (confidence = 0.5):\n",
      "  Stocks         :   8.67%\n",
      "  Bonds          :   4.45%\n",
      "  Gold           :   4.45%\n",
      "  Real Estate    :   6.19%\n",
      "\n",
      "Posterior Returns (confidence = 1.0):\n",
      "  Stocks         :   9.00%\n",
      "  Bonds          :   4.68%\n",
      "  Gold           :   4.18%\n",
      "  Real Estate    :   6.28%\n",
      "\n",
      "Posterior Returns (confidence = 2.0):\n",
      "  Stocks         :   9.33%\n",
      "  Bonds          :   4.90%\n",
      "  Gold           :   3.90%\n",
      "  Real Estate    :   6.37%\n",
      "\n",
      "Posterior Returns (confidence = 5.0):\n",
      "  Stocks         :   9.67%\n",
      "  Bonds          :   5.13%\n",
      "  Gold           :   3.63%\n",
      "  Real Estate    :   6.47%\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: Qualitative Views\n",
      "================================================================================\n",
      "\n",
      "Prior Expected Returns:\n",
      "  Tech           :  12.00%\n",
      "  Energy         :   8.00%\n",
      "  Finance        :  10.00%\n",
      "\n",
      "Qualitative Views:\n",
      "  1. Very bullish on Tech\n",
      "  2. Bearish on Energy\n",
      "  3. Bullish: Tech will outperform Finance\n",
      "\n",
      "Quantified Views (Q vector): [ 72.         -16.49489743  33.6227766 ]%\n",
      "\n",
      "Posterior Expected Returns:\n",
      "  Tech           :  48.00%\n",
      "  Energy         :  -6.70%\n",
      "  Finance        :  27.03%\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 3: Scenario Analysis (Full Confidence)\n",
      "================================================================================\n",
      "\n",
      "Prior Expected Returns:\n",
      "  Asset A        :   7.00%\n",
      "  Asset B        :   5.00%\n",
      "  Asset C        :   6.00%\n",
      "\n",
      "Scenario (Full Confidence):\n",
      "  Asset A: 10.0%\n",
      "  Asset B:  4.0%\n",
      "\n",
      "Posterior Expected Returns:\n",
      "  Asset A        :  10.00%\n",
      "  Asset B        :   4.00%\n",
      "  Asset C        :   6.27%\n",
      "\n",
      "Note: With very high confidence, Asset A ≈ 10% and Asset B ≈ 4%\n",
      "      Asset C is adjusted through correlation structure\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 4: Confidence Level Sensitivity\n",
      "================================================================================\n",
      "\n",
      "Prior: Asset 1 = 8%, Asset 2 = 6%\n",
      "View:  Asset 1 = 12%\n",
      "\n",
      "Posterior Asset 1 returns at different confidence levels:\n",
      "  Confidence =    0.1:  8.364%\n",
      "  Confidence =    0.5:  9.333%\n",
      "  Confidence =    1.0: 10.000%\n",
      "  Confidence =    2.0: 10.667%\n",
      "  Confidence =    5.0: 11.333%\n",
      "  Confidence =   10.0: 11.636%\n",
      "  Confidence =  100.0: 11.960%\n",
      "\n",
      "Observation:\n",
      "  - Low confidence  → stays close to prior (8%)\n",
      "  - High confidence → approaches view (12%)\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 5: Original vs Market Formulation\n",
      "================================================================================\n",
      "\n",
      "View: Asset 1 will return 10%\n",
      "Prior: [8. 6. 7.]%\n",
      "\n",
      "Original Formulation (with tau=0.025):\n",
      "  Expected Returns: [8.04878049 6.01219512 7.01219512]%\n",
      "  Posterior Variance (Asset 1): 4.0976%²\n",
      "\n",
      "Market Formulation (no tau needed):\n",
      "  Expected Returns: [9.   6.25 7.25]%\n",
      "  Posterior Variance (Asset 1): 2.0000%²\n",
      "\n",
      "Difference:\n",
      "  Expected Returns: [-0.95121951 -0.23780488 -0.23780488]%\n",
      "  Variance: 2.0976%²\n",
      "\n",
      "Note: Market formulation is cleaner (no tau parameter in posterior)\n",
      "      and has better limiting behavior for scenario analysis\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 6: Equilibrium Returns from Market Capitalization\n",
      "================================================================================\n",
      "\n",
      "Market Capitalization Weights:\n",
      "  US             :  55.0%\n",
      "  Europe         :  25.0%\n",
      "  Japan          :  10.0%\n",
      "  Emerging       :  10.0%\n",
      "\n",
      "Implied Equilibrium Returns:\n",
      "\n",
      "  Risk Aversion λ = 1.5:\n",
      "    US             :   9.98%\n",
      "    Europe         :   8.13%\n",
      "    Japan          :   6.75%\n",
      "    Emerging       :   9.60%\n",
      "\n",
      "  Risk Aversion λ = 2.5:\n",
      "    US             :  16.62%\n",
      "    Europe         :  13.55%\n",
      "    Japan          :  11.25%\n",
      "    Emerging       :  16.00%\n",
      "\n",
      "  Risk Aversion λ = 3.5:\n",
      "    US             :  23.28%\n",
      "    Europe         :  18.97%\n",
      "    Japan          :  15.75%\n",
      "    Emerging       :  22.40%\n",
      "\n",
      "Note: Higher risk aversion → higher implied returns\n",
      "      (investors require more return to hold risky assets)\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 7: Relative Confidence Levels\n",
      "================================================================================\n",
      "\n",
      "Prior Expected Returns:\n",
      "  Stock A        :   8.00%\n",
      "  Stock B        :   7.00%\n",
      "  Stock C        :   6.00%\n",
      "\n",
      "Views:\n",
      "  1. Stock A = 12% (HIGH confidence)\n",
      "  2. Stock B =  9% (LOW confidence)\n",
      "\n",
      "--- Equal Confidence ---\n",
      "  Stock A        :  10.67%\n",
      "  Stock B        :   8.33%\n",
      "  Stock C        :   6.85%\n",
      "\n",
      "--- Relative Confidence (3:1) ---\n",
      "  Stock A        :  10.65%\n",
      "  Stock B        :   7.72%\n",
      "  Stock C        :   6.68%\n",
      "\n",
      "Observation:\n",
      "  Stock A moves more toward 12% (higher confidence)\n",
      "  Stock B moves less toward 9% (lower confidence)\n",
      "\n",
      "================================================================================\n",
      "All examples completed successfully!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Black-Litterman Model Implementation\n",
    "Based on Meucci (2008): \"The Black-Litterman Approach: Original Model and Extensions\"\n",
    "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1117574\n",
    "\n",
    "This implementation follows the market formulation (Section 3) which is more intuitive\n",
    "and handles null-confidence and full-confidence limits correctly.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "\n",
    "class BlackLittermanModel:\n",
    "    \"\"\"\n",
    "    Black-Litterman portfolio optimization model.\n",
    "\n",
    "    This class implements both the original BL formulation (Section 2) and\n",
    "    the market-based formulation (Section 3) from Meucci's paper.\n",
    "\n",
    "    The market formulation is recommended as it:\n",
    "    1. Eliminates the need for the tau parameter in posterior calculations\n",
    "    2. Correctly handles limiting cases (null and full confidence)\n",
    "    3. Integrates naturally with scenario analysis\n",
    "\n",
    "    Attributes:\n",
    "        pi (np.ndarray): Prior expected returns (equilibrium or reference)\n",
    "        sigma (np.ndarray): Covariance matrix of asset returns\n",
    "        tau (float): Uncertainty scalar for prior (only used in original formulation)\n",
    "        use_market_formulation (bool): If True, uses market-based BL (recommended)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pi: np.ndarray,\n",
    "        sigma: np.ndarray,\n",
    "        tau: float = 0.025,\n",
    "        use_market_formulation: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Black-Litterman model.\n",
    "\n",
    "        Args:\n",
    "            pi: Prior expected returns (N x 1 array or N-length vector)\n",
    "                Typically derived from equilibrium (CAPM) as pi = 2*lambda*Sigma*w_eq\n",
    "            sigma: Covariance matrix of returns (N x N)\n",
    "            tau: Scalar representing uncertainty in prior (typically 0.01 to 0.05)\n",
    "                 Meucci suggests tau ≈ 1/T where T is the time series length\n",
    "                 Only used in original formulation\n",
    "            use_market_formulation: If True, uses market-based formulation (Section 3)\n",
    "                                   If False, uses original formulation (Section 2)\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays and validate inputs\n",
    "        self.pi = np.asarray(pi).flatten()\n",
    "        self.sigma = np.asarray(sigma)\n",
    "        self.tau = tau\n",
    "        self.use_market_formulation = use_market_formulation\n",
    "\n",
    "        # Validate dimensions\n",
    "        n_assets = len(self.pi)\n",
    "        if self.sigma.shape != (n_assets, n_assets):\n",
    "            raise ValueError(\n",
    "                f\"Sigma shape {self.sigma.shape} incompatible with pi length {n_assets}\"\n",
    "            )\n",
    "\n",
    "        # Check if sigma is symmetric positive definite\n",
    "        if not np.allclose(self.sigma, self.sigma.T):\n",
    "            warnings.warn(\"Covariance matrix is not symmetric. Symmetrizing.\")\n",
    "            self.sigma = (self.sigma + self.sigma.T) / 2\n",
    "\n",
    "        # Check positive definiteness\n",
    "        eigenvalues = np.linalg.eigvalsh(self.sigma)\n",
    "        if np.any(eigenvalues <= 0):\n",
    "            warnings.warn(\n",
    "                f\"Covariance matrix has non-positive eigenvalues: {eigenvalues[eigenvalues <= 0]}\"\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_equilibrium_returns(\n",
    "        w_eq: np.ndarray,\n",
    "        sigma: np.ndarray,\n",
    "        risk_aversion: float = 2.5\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute equilibrium expected returns from market weights.\n",
    "\n",
    "        Based on equation (5) in Meucci:\n",
    "        π = 2λΣw_eq\n",
    "\n",
    "        where λ is the market risk aversion parameter.\n",
    "\n",
    "        Args:\n",
    "            w_eq: Market equilibrium weights (N x 1 or N-length)\n",
    "            sigma: Covariance matrix (N x N)\n",
    "            risk_aversion: Market risk aversion parameter (λ)\n",
    "                          Typical values: 2-3 for equity markets\n",
    "                          Black-Litterman suggest λ ≈ 2.5\n",
    "\n",
    "        Returns:\n",
    "            Equilibrium expected returns (N x 1 array)\n",
    "        \"\"\"\n",
    "        w_eq = np.asarray(w_eq).flatten()\n",
    "        sigma = np.asarray(sigma)\n",
    "\n",
    "        # Equation (5): π = 2λΣw_eq\n",
    "        pi = 2 * risk_aversion * sigma @ w_eq\n",
    "\n",
    "        return pi\n",
    "\n",
    "    def compute_posterior_original(\n",
    "        self,\n",
    "        P: np.ndarray,\n",
    "        Q: np.ndarray,\n",
    "        Omega: Optional[np.ndarray] = None,\n",
    "        confidence: float = 1.0,\n",
    "        relative_confidence: Optional[np.ndarray] = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute posterior distribution using ORIGINAL Black-Litterman formulation.\n",
    "\n",
    "        This implements equations (20) and (21) from Section 2:\n",
    "\n",
    "        μ_BL = π + τΣP'(τPΣP' + Ω)^(-1)(Q - Pπ)\n",
    "        Σ_BL = (1+τ)Σ - τ²ΣP'(τPΣP' + Ω)^(-1)PΣ\n",
    "\n",
    "        Args:\n",
    "            P: View pick matrix (K x N) where K = number of views\n",
    "               Each row defines a portfolio for one view\n",
    "            Q: View expected returns (K x 1 or K-length)\n",
    "               Expected returns on the view portfolios\n",
    "            Omega: Uncertainty matrix for views (K x K)\n",
    "                   If None, computed from equation (12) or (13)\n",
    "            confidence: Overall confidence level c in equations (12-13)\n",
    "                       Higher values = more confident in views\n",
    "            relative_confidence: Relative confidence for each view (K-length)\n",
    "                                Used in equation (13) as vector u\n",
    "\n",
    "        Returns:\n",
    "            mu_bl: Posterior expected returns (N x 1)\n",
    "            sigma_bl: Posterior covariance matrix (N x N)\n",
    "        \"\"\"\n",
    "        # Convert inputs to numpy arrays\n",
    "        P = np.asarray(P)\n",
    "        Q = np.asarray(Q).flatten()\n",
    "\n",
    "        K, N = P.shape\n",
    "        if len(Q) != K:\n",
    "            raise ValueError(f\"Q length {len(Q)} must match P rows {K}\")\n",
    "        if N != len(self.pi):\n",
    "            raise ValueError(f\"P columns {N} must match asset count {len(self.pi)}\")\n",
    "\n",
    "        # Compute Omega if not provided\n",
    "        if Omega is None:\n",
    "            Omega = self._compute_omega(P, confidence, relative_confidence)\n",
    "        else:\n",
    "            Omega = np.asarray(Omega)\n",
    "            # Handle scalar Omega for single view\n",
    "            if Omega.ndim == 0 and K == 1:\n",
    "                Omega = Omega.reshape((1, 1))\n",
    "            elif Omega.shape != (K, K):\n",
    "                raise ValueError(f\"Omega shape {Omega.shape} must be ({K}, {K})\")\n",
    "\n",
    "        # Compute intermediate term: τPΣP' + Ω\n",
    "        tau_P_sigma_Pt = self.tau * P @ self.sigma @ P.T\n",
    "        M = tau_P_sigma_Pt + Omega\n",
    "\n",
    "        # Compute M^(-1) using stable inversion\n",
    "        try:\n",
    "            M_inv = np.linalg.inv(M)\n",
    "        except np.linalg.LinAlgError:\n",
    "            warnings.warn(\"Matrix M is singular, using pseudo-inverse\")\n",
    "            M_inv = np.linalg.pinv(M)\n",
    "\n",
    "        # Equation (20): μ_BL = π + τΣP'(τPΣP' + Ω)^(-1)(Q - Pπ)\n",
    "        view_adjustment = Q - P @ self.pi\n",
    "        mu_bl = self.pi + self.tau * self.sigma @ P.T @ M_inv @ view_adjustment\n",
    "\n",
    "        # Equation (21): Σ_BL = (1+τ)Σ - τ²ΣP'(τPΣP' + Ω)^(-1)PΣ\n",
    "        sigma_bl = (1 + self.tau) * self.sigma\n",
    "        sigma_bl -= self.tau**2 * self.sigma @ P.T @ M_inv @ P @ self.sigma\n",
    "\n",
    "        return mu_bl, sigma_bl\n",
    "\n",
    "    def compute_posterior_market(\n",
    "        self,\n",
    "        P: np.ndarray,\n",
    "        Q: np.ndarray,\n",
    "        Omega: Optional[np.ndarray] = None,\n",
    "        confidence: float = 1.0,\n",
    "        relative_confidence: Optional[np.ndarray] = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute posterior distribution using MARKET-BASED formulation.\n",
    "\n",
    "        This implements equations (32) and (33) from Section 3:\n",
    "\n",
    "        μ_BL^m = π + ΣP'(PΣP' + Ω)^(-1)(Q - Pπ)\n",
    "        Σ_BL^m = Σ - ΣP'(PΣP' + Ω)^(-1)PΣ\n",
    "\n",
    "        This formulation:\n",
    "        - Does not require tau in posterior computation\n",
    "        - Correctly reduces to prior when Ω → ∞ (no confidence)\n",
    "        - Correctly reduces to conditional when Ω → 0 (full confidence)\n",
    "        - Integrates naturally with scenario analysis\n",
    "\n",
    "        Args:\n",
    "            P: View pick matrix (K x N)\n",
    "            Q: View expected returns (K x 1 or K-length)\n",
    "            Omega: Uncertainty matrix for views (K x K)\n",
    "            confidence: Overall confidence level\n",
    "            relative_confidence: Relative confidence for each view\n",
    "\n",
    "        Returns:\n",
    "            mu_bl: Posterior expected returns (N x 1)\n",
    "            sigma_bl: Posterior covariance matrix (N x N)\n",
    "        \"\"\"\n",
    "        # Convert inputs to numpy arrays\n",
    "        P = np.asarray(P)\n",
    "        Q = np.asarray(Q).flatten()\n",
    "\n",
    "        K, N = P.shape\n",
    "        if len(Q) != K:\n",
    "            raise ValueError(f\"Q length {len(Q)} must match P rows {K}\")\n",
    "        if N != len(self.pi):\n",
    "            raise ValueError(f\"P columns {N} must match asset count {len(self.pi)}\")\n",
    "\n",
    "        # Compute Omega if not provided\n",
    "        if Omega is None:\n",
    "            Omega = self._compute_omega(P, confidence, relative_confidence)\n",
    "        else:\n",
    "            Omega = np.asarray(Omega)\n",
    "            # Handle scalar Omega for single view\n",
    "            if Omega.ndim == 0 and K == 1:\n",
    "                Omega = Omega.reshape((1, 1))\n",
    "            elif Omega.shape != (K, K):\n",
    "                raise ValueError(f\"Omega shape {Omega.shape} must be ({K}, {K})\")\n",
    "\n",
    "        # Compute intermediate term: PΣP' + Ω\n",
    "        P_sigma_Pt = P @ self.sigma @ P.T\n",
    "        M = P_sigma_Pt + Omega\n",
    "\n",
    "        # Compute M^(-1) using stable inversion\n",
    "        try:\n",
    "            M_inv = np.linalg.inv(M)\n",
    "        except np.linalg.LinAlgError:\n",
    "            warnings.warn(\"Matrix M is singular, using pseudo-inverse\")\n",
    "            M_inv = np.linalg.pinv(M)\n",
    "\n",
    "        # Equation (32): μ_BL^m = π + ΣP'(PΣP' + Ω)^(-1)(Q - Pπ)\n",
    "        view_adjustment = Q - P @ self.pi\n",
    "        mu_bl = self.pi + self.sigma @ P.T @ M_inv @ view_adjustment\n",
    "\n",
    "        # Equation (33): Σ_BL^m = Σ - ΣP'(PΣP' + Ω)^(-1)PΣ\n",
    "        sigma_bl = self.sigma - self.sigma @ P.T @ M_inv @ P @ self.sigma\n",
    "\n",
    "        return mu_bl, sigma_bl\n",
    "\n",
    "    def compute_posterior(\n",
    "        self,\n",
    "        P: np.ndarray,\n",
    "        Q: np.ndarray,\n",
    "        Omega: Optional[np.ndarray] = None,\n",
    "        confidence: float = 1.0,\n",
    "        relative_confidence: Optional[np.ndarray] = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute posterior distribution using the selected formulation.\n",
    "\n",
    "        This is the main interface method that delegates to either the original\n",
    "        or market-based formulation based on initialization.\n",
    "\n",
    "        Args:\n",
    "            P: View pick matrix (K x N)\n",
    "               Example: [[0, 1, 0, 0]] for a view on asset 2\n",
    "                       [[1, -1, 0, 0]] for a view that asset 1 outperforms asset 2\n",
    "            Q: View expected returns (K x 1 or K-length)\n",
    "               Example: [0.05] for 5% expected return on the view\n",
    "            Omega: Uncertainty matrix for views (K x K)\n",
    "                   If None, computed automatically\n",
    "            confidence: Overall confidence level (higher = more confident)\n",
    "                       Typical range: 0.1 to 10\n",
    "            relative_confidence: Relative confidence for each view (K-length)\n",
    "                                Can be used to express different confidence levels\n",
    "\n",
    "        Returns:\n",
    "            mu_bl: Posterior expected returns (N x 1)\n",
    "            sigma_bl: Posterior covariance matrix (N x N)\n",
    "\n",
    "        Example:\n",
    "            >>> # Single view: Asset 2 will return 5%\n",
    "            >>> P = np.array([[0, 1, 0, 0]])\n",
    "            >>> Q = np.array([0.05])\n",
    "            >>> mu_bl, sigma_bl = bl.compute_posterior(P, Q, confidence=2.0)\n",
    "        \"\"\"\n",
    "        if self.use_market_formulation:\n",
    "            return self.compute_posterior_market(\n",
    "                P, Q, Omega, confidence, relative_confidence\n",
    "            )\n",
    "        else:\n",
    "            return self.compute_posterior_original(\n",
    "                P, Q, Omega, confidence, relative_confidence\n",
    "            )\n",
    "\n",
    "    def _compute_omega(\n",
    "        self,\n",
    "        P: np.ndarray,\n",
    "        confidence: float = 1.0,\n",
    "        relative_confidence: Optional[np.ndarray] = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the view uncertainty matrix Omega.\n",
    "\n",
    "        Implements equations (12) and (13) from the paper:\n",
    "\n",
    "        Simple version (12): Ω = (1/c) * PΣP'\n",
    "\n",
    "        Advanced version (13): Ω = (1/c) * diag(u) * PΣP' * diag(u)\n",
    "\n",
    "        where c is the overall confidence and u is the relative confidence vector.\n",
    "\n",
    "        Args:\n",
    "            P: View pick matrix (K x N)\n",
    "            confidence: Overall confidence parameter c\n",
    "            relative_confidence: Relative confidence vector u (K-length)\n",
    "\n",
    "        Returns:\n",
    "            Omega: View uncertainty matrix (K x K)\n",
    "        \"\"\"\n",
    "        # Compute base uncertainty from market volatilities\n",
    "        P_sigma_Pt = P @ self.sigma @ P.T\n",
    "\n",
    "        if relative_confidence is not None:\n",
    "            # Equation (13): Ω = (1/c) * diag(u) * PΣP' * diag(u)\n",
    "            u = np.asarray(relative_confidence).flatten()\n",
    "            if len(u) != P.shape[0]:\n",
    "                raise ValueError(\n",
    "                    f\"relative_confidence length {len(u)} must match views {P.shape[0]}\"\n",
    "                )\n",
    "            u_diag = np.diag(u)\n",
    "            Omega = (1 / confidence) * u_diag @ P_sigma_Pt @ u_diag\n",
    "        else:\n",
    "            # Equation (12): Ω = (1/c) * PΣP'\n",
    "            Omega = (1 / confidence) * P_sigma_Pt\n",
    "\n",
    "        return Omega\n",
    "\n",
    "    def set_qualitative_views(\n",
    "        self,\n",
    "        P: np.ndarray,\n",
    "        view_types: list,\n",
    "        alpha: float = 1.0,\n",
    "        beta: float = 2.0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert qualitative views to quantitative Q vector.\n",
    "\n",
    "        Implements equation (11) from the paper:\n",
    "        Q_k = (Pπ)_k + η_k * sqrt((PΣP')_{k,k})\n",
    "\n",
    "        where η ∈ {-β, -α, +α, +β} for:\n",
    "        - \"very bearish\" (-β)\n",
    "        - \"bearish\" (-α)\n",
    "        - \"bullish\" (+α)\n",
    "        - \"very bullish\" (+β)\n",
    "\n",
    "        Args:\n",
    "            P: View pick matrix (K x N)\n",
    "            view_types: List of strings from:\n",
    "                       ['very_bearish', 'bearish', 'bullish', 'very_bullish']\n",
    "            alpha: Parameter for bullish/bearish (typically 1.0)\n",
    "            beta: Parameter for very bullish/bearish (typically 2.0)\n",
    "\n",
    "        Returns:\n",
    "            Q: Quantitative view vector (K x 1)\n",
    "\n",
    "        Example:\n",
    "            >>> P = np.array([[1, -1, 0], [0, 1, 0]])\n",
    "            >>> types = ['bullish', 'very_bullish']\n",
    "            >>> Q = bl.set_qualitative_views(P, types)\n",
    "        \"\"\"\n",
    "        P = np.asarray(P)\n",
    "        K = P.shape[0]\n",
    "\n",
    "        if len(view_types) != K:\n",
    "            raise ValueError(\n",
    "                f\"view_types length {len(view_types)} must match views {K}\"\n",
    "            )\n",
    "\n",
    "        # Map view types to eta values\n",
    "        eta_map = {\n",
    "            'very_bearish': -beta,\n",
    "            'bearish': -alpha,\n",
    "            'bullish': alpha,\n",
    "            'very_bullish': beta\n",
    "        }\n",
    "\n",
    "        # Compute base expectations from prior\n",
    "        P_pi = P @ self.pi\n",
    "\n",
    "        # Compute volatility of view portfolios\n",
    "        P_sigma_Pt = P @ self.sigma @ P.T\n",
    "        view_volatilities = np.sqrt(np.diag(P_sigma_Pt))\n",
    "\n",
    "        # Equation (11): Q_k = (Pπ)_k + η_k * sqrt((PΣP')_{k,k})\n",
    "        Q = np.zeros(K)\n",
    "        for k, view_type in enumerate(view_types):\n",
    "            if view_type not in eta_map:\n",
    "                raise ValueError(\n",
    "                    f\"view_type '{view_type}' not recognized. \"\n",
    "                    f\"Use one of: {list(eta_map.keys())}\"\n",
    "                )\n",
    "            eta = eta_map[view_type]\n",
    "            Q[k] = P_pi[k] + eta * view_volatilities[k]\n",
    "\n",
    "        return Q\n",
    "\n",
    "    def validate_posterior(\n",
    "        self,\n",
    "        sigma_bl: np.ndarray,\n",
    "        check_psd: bool = True,\n",
    "        tolerance: float = 1e-8\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Validate the posterior covariance matrix.\n",
    "\n",
    "        Checks:\n",
    "        1. Symmetry\n",
    "        2. Positive semi-definiteness\n",
    "        3. Reasonable conditioning\n",
    "\n",
    "        Args:\n",
    "            sigma_bl: Posterior covariance matrix\n",
    "            check_psd: If True, check positive semi-definiteness\n",
    "            tolerance: Numerical tolerance for checks\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with validation results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'is_symmetric': False,\n",
    "            'is_psd': None,\n",
    "            'min_eigenvalue': None,\n",
    "            'condition_number': None,\n",
    "            'warnings': []\n",
    "        }\n",
    "\n",
    "        # Check symmetry\n",
    "        if np.allclose(sigma_bl, sigma_bl.T, atol=tolerance):\n",
    "            results['is_symmetric'] = True\n",
    "        else:\n",
    "            results['warnings'].append(\"Covariance matrix is not symmetric\")\n",
    "\n",
    "        if check_psd:\n",
    "            # Check positive semi-definiteness\n",
    "            eigenvalues = np.linalg.eigvalsh(sigma_bl)\n",
    "            results['min_eigenvalue'] = np.min(eigenvalues)\n",
    "\n",
    "            if np.all(eigenvalues >= -tolerance):\n",
    "                results['is_psd'] = True\n",
    "            else:\n",
    "                results['is_psd'] = False\n",
    "                results['warnings'].append(\n",
    "                    f\"Covariance has negative eigenvalues: min = {results['min_eigenvalue']}\"\n",
    "                )\n",
    "\n",
    "            # Check condition number\n",
    "            max_eig = np.max(eigenvalues)\n",
    "            if results['min_eigenvalue'] > tolerance:\n",
    "                results['condition_number'] = max_eig / results['min_eigenvalue']\n",
    "                if results['condition_number'] > 1e10:\n",
    "                    results['warnings'].append(\n",
    "                        f\"Poor conditioning: {results['condition_number']:.2e}\"\n",
    "                    )\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def create_view_matrix(\n",
    "    n_assets: int,\n",
    "    absolute_views: Optional[dict] = None,\n",
    "    relative_views: Optional[list] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper function to create the P matrix from intuitive view specifications.\n",
    "\n",
    "    Args:\n",
    "        n_assets: Total number of assets\n",
    "        absolute_views: Dict mapping asset indices to weights\n",
    "                       Example: {1: 1.0} for a view on asset 1\n",
    "        relative_views: List of (asset_i, asset_j, weight_i, weight_j) tuples\n",
    "                       Example: [(0, 1, 1.0, -1.0)] for asset 0 outperforms asset 1\n",
    "\n",
    "    Returns:\n",
    "        P matrix (K x N) where K is total number of views\n",
    "\n",
    "    Example:\n",
    "        >>> # View 1: Asset 2 will return X%\n",
    "        >>> # View 2: Asset 0 will outperform Asset 1\n",
    "        >>> P = create_view_matrix(\n",
    "        ...     n_assets=4,\n",
    "        ...     absolute_views={2: 1.0},\n",
    "        ...     relative_views=[(0, 1, 1.0, -1.0)]\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    views = []\n",
    "\n",
    "    # Add absolute views\n",
    "    if absolute_views:\n",
    "        for asset_idx, weight in absolute_views.items():\n",
    "            if asset_idx >= n_assets or asset_idx < 0:\n",
    "                raise ValueError(f\"Asset index {asset_idx} out of range [0, {n_assets})\")\n",
    "            view = np.zeros(n_assets)\n",
    "            view[asset_idx] = weight\n",
    "            views.append(view)\n",
    "\n",
    "    # Add relative views\n",
    "    if relative_views:\n",
    "        for asset_i, asset_j, weight_i, weight_j in relative_views:\n",
    "            if asset_i >= n_assets or asset_i < 0:\n",
    "                raise ValueError(f\"Asset index {asset_i} out of range [0, {n_assets})\")\n",
    "            if asset_j >= n_assets or asset_j < 0:\n",
    "                raise ValueError(f\"Asset index {asset_j} out of range [0, {n_assets})\")\n",
    "            view = np.zeros(n_assets)\n",
    "            view[asset_i] = weight_i\n",
    "            view[asset_j] = weight_j\n",
    "            views.append(view)\n",
    "\n",
    "    if not views:\n",
    "        raise ValueError(\"No views specified\")\n",
    "\n",
    "    return np.array(views)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def example_1_basic_usage():\n",
    "    \"\"\"\n",
    "    Example 1: Basic usage with absolute and relative views\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 1: Basic Black-Litterman Usage\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Simple 4-asset portfolio\n",
    "    n_assets = 4\n",
    "    asset_names = ['Stocks', 'Bonds', 'Gold', 'Real Estate']\n",
    "\n",
    "    # Prior expected returns (could be from equilibrium or other model)\n",
    "    pi = np.array([0.08, 0.04, 0.05, 0.06])\n",
    "\n",
    "    # Covariance matrix (annualized)\n",
    "    sigma = np.array([\n",
    "        [0.040, 0.008, 0.002, 0.010],\n",
    "        [0.008, 0.010, 0.001, 0.004],\n",
    "        [0.002, 0.001, 0.015, 0.002],\n",
    "        [0.010, 0.004, 0.002, 0.025]\n",
    "    ])\n",
    "\n",
    "    # Initialize model (using market formulation)\n",
    "    bl = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "\n",
    "    # Express views:\n",
    "    # View 1: Stocks will return 10%\n",
    "    # View 2: Bonds will outperform Gold by 2%\n",
    "    P = create_view_matrix(\n",
    "        n_assets=n_assets,\n",
    "        absolute_views={0: 1.0},  # Stocks\n",
    "        relative_views=[(1, 2, 1.0, -1.0)]  # Bonds - Gold\n",
    "    )\n",
    "    Q = np.array([0.10, 0.02])\n",
    "\n",
    "    print(\"\\nPrior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {pi[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nViews:\")\n",
    "    print(\"  1. Stocks will return 10.0%\")\n",
    "    print(\"  2. Bonds will outperform Gold by 2.0%\")\n",
    "\n",
    "    # Compute posterior with different confidence levels\n",
    "    for conf in [0.5, 1.0, 2.0, 5.0]:\n",
    "        mu_bl, sigma_bl = bl.compute_posterior(P, Q, confidence=conf)\n",
    "        print(f\"\\nPosterior Returns (confidence = {conf}):\")\n",
    "        for i, name in enumerate(asset_names):\n",
    "            print(f\"  {name:15s}: {mu_bl[i]*100:6.2f}%\")\n",
    "\n",
    "\n",
    "def example_2_qualitative_views():\n",
    "    \"\"\"\n",
    "    Example 2: Using qualitative views (bullish/bearish)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 2: Qualitative Views\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 3-asset portfolio\n",
    "    n_assets = 3\n",
    "    asset_names = ['Tech', 'Energy', 'Finance']\n",
    "\n",
    "    pi = np.array([0.12, 0.08, 0.10])\n",
    "    sigma = np.array([\n",
    "        [0.09, 0.02, 0.03],\n",
    "        [0.02, 0.06, 0.02],\n",
    "        [0.03, 0.02, 0.07]\n",
    "    ])\n",
    "\n",
    "    bl = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "\n",
    "    # Express qualitative views\n",
    "    # View 1: Very bullish on Tech\n",
    "    # View 2: Bearish on Energy\n",
    "    # View 3: Tech will outperform Finance (bullish on spread)\n",
    "    P = create_view_matrix(\n",
    "        n_assets=n_assets,\n",
    "        absolute_views={0: 1.0, 1: 1.0},  # Tech, Energy\n",
    "        relative_views=[(0, 2, 1.0, -1.0)]  # Tech - Finance\n",
    "    )\n",
    "\n",
    "    view_types = ['very_bullish', 'bearish', 'bullish']\n",
    "    Q = bl.set_qualitative_views(P, view_types, alpha=1.0, beta=2.0)\n",
    "\n",
    "    print(\"\\nPrior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {pi[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nQualitative Views:\")\n",
    "    print(\"  1. Very bullish on Tech\")\n",
    "    print(\"  2. Bearish on Energy\")\n",
    "    print(\"  3. Bullish: Tech will outperform Finance\")\n",
    "\n",
    "    print(f\"\\nQuantified Views (Q vector): {Q*100}%\")\n",
    "\n",
    "    mu_bl, sigma_bl = bl.compute_posterior(P, Q, confidence=1.5)\n",
    "\n",
    "    print(\"\\nPosterior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {mu_bl[i]*100:6.2f}%\")\n",
    "\n",
    "\n",
    "def example_3_scenario_analysis():\n",
    "    \"\"\"\n",
    "    Example 3: Scenario analysis (full confidence limit)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 3: Scenario Analysis (Full Confidence)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 3-asset portfolio\n",
    "    asset_names = ['Asset A', 'Asset B', 'Asset C']\n",
    "\n",
    "    pi = np.array([0.07, 0.05, 0.06])\n",
    "    sigma = np.array([\n",
    "        [0.04, 0.01, 0.01],\n",
    "        [0.01, 0.03, 0.01],\n",
    "        [0.01, 0.01, 0.05]\n",
    "    ])\n",
    "\n",
    "    bl = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "\n",
    "    # Scenario: Asset A returns 10% and Asset B returns 4%\n",
    "    P = create_view_matrix(\n",
    "        n_assets=3,\n",
    "        absolute_views={0: 1.0, 1: 1.0}\n",
    "    )\n",
    "    Q = np.array([0.10, 0.04])\n",
    "\n",
    "    print(\"\\nPrior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {pi[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nScenario (Full Confidence):\")\n",
    "    print(\"  Asset A: 10.0%\")\n",
    "    print(\"  Asset B:  4.0%\")\n",
    "\n",
    "    # Very high confidence approximates scenario analysis\n",
    "    mu_bl, sigma_bl = bl.compute_posterior(P, Q, confidence=1000.0)\n",
    "\n",
    "    print(\"\\nPosterior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {mu_bl[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nNote: With very high confidence, Asset A ≈ 10% and Asset B ≈ 4%\")\n",
    "    print(\"      Asset C is adjusted through correlation structure\")\n",
    "\n",
    "\n",
    "def example_4_confidence_sensitivity():\n",
    "    \"\"\"\n",
    "    Example 4: Sensitivity to confidence levels\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 4: Confidence Level Sensitivity\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Simple 2-asset case for clarity\n",
    "    asset_names = ['Asset 1', 'Asset 2']\n",
    "\n",
    "    pi = np.array([0.08, 0.06])\n",
    "    sigma = np.array([\n",
    "        [0.04, 0.01],\n",
    "        [0.01, 0.03]\n",
    "    ])\n",
    "\n",
    "    bl = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "\n",
    "    # View: Asset 1 will return 12%\n",
    "    P = np.array([[1, 0]])\n",
    "    Q = np.array([0.12])\n",
    "\n",
    "    print(\"\\nPrior: Asset 1 = 8%, Asset 2 = 6%\")\n",
    "    print(\"View:  Asset 1 = 12%\")\n",
    "    print(\"\\nPosterior Asset 1 returns at different confidence levels:\")\n",
    "\n",
    "    confidences = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 100.0]\n",
    "    results = []\n",
    "\n",
    "    for conf in confidences:\n",
    "        mu_bl, _ = bl.compute_posterior(P, Q, confidence=conf)\n",
    "        results.append(mu_bl[0])\n",
    "        print(f\"  Confidence = {conf:6.1f}: {mu_bl[0]*100:6.3f}%\")\n",
    "\n",
    "    print(\"\\nObservation:\")\n",
    "    print(\"  - Low confidence  → stays close to prior (8%)\")\n",
    "    print(\"  - High confidence → approaches view (12%)\")\n",
    "\n",
    "\n",
    "def example_5_formulation_comparison():\n",
    "    \"\"\"\n",
    "    Example 5: Compare original vs market formulation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 5: Original vs Market Formulation\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 3-asset portfolio\n",
    "    pi = np.array([0.08, 0.06, 0.07])\n",
    "    sigma = np.array([\n",
    "        [0.04, 0.01, 0.01],\n",
    "        [0.01, 0.03, 0.01],\n",
    "        [0.01, 0.01, 0.05]\n",
    "    ])\n",
    "\n",
    "    # View: Asset 1 will return 10%\n",
    "    P = np.array([[1, 0, 0]])\n",
    "    Q = np.array([0.10])\n",
    "\n",
    "    print(\"\\nView: Asset 1 will return 10%\")\n",
    "    print(f\"Prior: {pi*100}%\\n\")\n",
    "\n",
    "    # Original formulation\n",
    "    bl_orig = BlackLittermanModel(pi, sigma, tau=0.025, use_market_formulation=False)\n",
    "    mu_orig, sigma_orig = bl_orig.compute_posterior(P, Q, confidence=1.0)\n",
    "\n",
    "    # Market formulation\n",
    "    bl_mkt = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "    mu_mkt, sigma_mkt = bl_mkt.compute_posterior(P, Q, confidence=1.0)\n",
    "\n",
    "    print(\"Original Formulation (with tau=0.025):\")\n",
    "    print(f\"  Expected Returns: {mu_orig*100}%\")\n",
    "    print(f\"  Posterior Variance (Asset 1): {sigma_orig[0,0]*100:.4f}%²\")\n",
    "\n",
    "    print(\"\\nMarket Formulation (no tau needed):\")\n",
    "    print(f\"  Expected Returns: {mu_mkt*100}%\")\n",
    "    print(f\"  Posterior Variance (Asset 1): {sigma_mkt[0,0]*100:.4f}%²\")\n",
    "\n",
    "    print(\"\\nDifference:\")\n",
    "    print(f\"  Expected Returns: {(mu_orig - mu_mkt)*100}%\")\n",
    "    print(f\"  Variance: {(sigma_orig[0,0] - sigma_mkt[0,0])*100:.4f}%²\")\n",
    "\n",
    "    print(\"\\nNote: Market formulation is cleaner (no tau parameter in posterior)\")\n",
    "    print(\"      and has better limiting behavior for scenario analysis\")\n",
    "\n",
    "\n",
    "def example_6_equilibrium_returns():\n",
    "    \"\"\"\n",
    "    Example 6: Computing equilibrium returns from market weights\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 6: Equilibrium Returns from Market Capitalization\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Example: Global equity markets\n",
    "    asset_names = ['US', 'Europe', 'Japan', 'Emerging']\n",
    "\n",
    "    # Market cap weights (example)\n",
    "    w_eq = np.array([0.55, 0.25, 0.10, 0.10])\n",
    "\n",
    "    # Historical covariance (example, annualized)\n",
    "    sigma = np.array([\n",
    "        [0.040, 0.025, 0.020, 0.030],\n",
    "        [0.025, 0.035, 0.018, 0.028],\n",
    "        [0.020, 0.018, 0.045, 0.025],\n",
    "        [0.030, 0.028, 0.025, 0.060]\n",
    "    ])\n",
    "\n",
    "    print(\"\\nMarket Capitalization Weights:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {w_eq[i]*100:5.1f}%\")\n",
    "\n",
    "    # Compute equilibrium returns for different risk aversion levels\n",
    "    print(\"\\nImplied Equilibrium Returns:\")\n",
    "\n",
    "    for risk_aversion in [1.5, 2.5, 3.5]:\n",
    "        pi = BlackLittermanModel.compute_equilibrium_returns(\n",
    "            w_eq, sigma, risk_aversion\n",
    "        )\n",
    "        print(f\"\\n  Risk Aversion λ = {risk_aversion}:\")\n",
    "        for i, name in enumerate(asset_names):\n",
    "            print(f\"    {name:15s}: {pi[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nNote: Higher risk aversion → higher implied returns\")\n",
    "    print(\"      (investors require more return to hold risky assets)\")\n",
    "\n",
    "\n",
    "def example_7_relative_confidence():\n",
    "    \"\"\"\n",
    "    Example 7: Using relative confidence levels for different views\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 7: Relative Confidence Levels\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 3-asset portfolio\n",
    "    asset_names = ['Stock A', 'Stock B', 'Stock C']\n",
    "\n",
    "    pi = np.array([0.08, 0.07, 0.06])\n",
    "    sigma = np.array([\n",
    "        [0.04, 0.01, 0.01],\n",
    "        [0.01, 0.03, 0.01],\n",
    "        [0.01, 0.01, 0.05]\n",
    "    ])\n",
    "\n",
    "    bl = BlackLittermanModel(pi, sigma, use_market_formulation=True)\n",
    "\n",
    "    # Two views:\n",
    "    # View 1: Stock A will return 12% (HIGH confidence)\n",
    "    # View 2: Stock B will return 9%  (LOW confidence)\n",
    "    P = create_view_matrix(\n",
    "        n_assets=3,\n",
    "        absolute_views={0: 1.0, 1: 1.0}\n",
    "    )\n",
    "    Q = np.array([0.12, 0.09])\n",
    "\n",
    "    print(\"\\nPrior Expected Returns:\")\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {pi[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nViews:\")\n",
    "    print(\"  1. Stock A = 12% (HIGH confidence)\")\n",
    "    print(\"  2. Stock B =  9% (LOW confidence)\")\n",
    "\n",
    "    # Equal confidence\n",
    "    print(\"\\n--- Equal Confidence ---\")\n",
    "    mu_equal, _ = bl.compute_posterior(P, Q, confidence=2.0)\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {mu_equal[i]*100:6.2f}%\")\n",
    "\n",
    "    # Relative confidence: View 1 is 3x more confident than View 2\n",
    "    print(\"\\n--- Relative Confidence (3:1) ---\")\n",
    "    relative_conf = np.array([1.0, 3.0])  # Higher value = LESS confident\n",
    "    mu_relative, _ = bl.compute_posterior(\n",
    "        P, Q, confidence=2.0, relative_confidence=relative_conf\n",
    "    )\n",
    "    for i, name in enumerate(asset_names):\n",
    "        print(f\"  {name:15s}: {mu_relative[i]*100:6.2f}%\")\n",
    "\n",
    "    print(\"\\nObservation:\")\n",
    "    print(\"  Stock A moves more toward 12% (higher confidence)\")\n",
    "    print(\"  Stock B moves less toward 9% (lower confidence)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run all examples\n",
    "    example_1_basic_usage()\n",
    "    example_2_qualitative_views()\n",
    "    example_3_scenario_analysis()\n",
    "    example_4_confidence_sensitivity()\n",
    "    example_5_formulation_comparison()\n",
    "    example_6_equilibrium_returns()\n",
    "    example_7_relative_confidence()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"All examples completed successfully!\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2p4vr6kneBb2",
    "outputId": "07fb89bb-39ba-4c7b-bfb4-0466b3ac13f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 1 root root 4096 Jan 16 14:24 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jsg8D3FDIR2"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtmWI8q5DJ7e"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5a2d5d7d064b4273b185dc15a342c663",
      "8f7a80aa27d649089a760aebe53ac686",
      "800c6874c0af49638ed77dbfbac9b45f",
      "252c78c445f94694b8e9cb2874da742e",
      "b5a9b7087e534efca455d163421fe020",
      "6327f087aa284aef8cb6c11654e7b22c",
      "215bcdc9c32f479790f247e2adb6e47b",
      "a6aaa7e9bd5f4290b78cb3d54cabd0ff",
      "0f4b1ecde60346f09570403d8cf3d947",
      "e95872fcdebe4c39a26a3d2c6da5d3f9",
      "13a633cdc05b40ca9721c7233cd5cf18",
      "6a30b5756c9146a68136b600c711b605",
      "3fffe5e0732640c6b4b3e8744feb6b8f",
      "f539b27db1a940d48d3cb4545ecb3cef",
      "4edbacd88eed41789fd7599ebc8c0417",
      "8579804bc3c54f2fab42254917a4bcd7",
      "1f5f5f65397343449fb2a253c197c1b2",
      "5824bd4aae864a61919359e89c05f4a9",
      "963def56754044468e16f80e10027da5",
      "82c8e1f846fc4129b12a29f5dfb5a1ec",
      "75cb5acc55c242a088a4e9079049a11c",
      "8a51befdc60d4ab090f4fdbd0ae60a8a"
     ]
    },
    "id": "QtGGqHhppGKJ",
    "outputId": "a95986df-f245-4f84-9879-d44ffbdd2864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BLACK-LITTERMAN + FINBERT PORTFOLIO OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "Mode: LIVE (real NewsAPI + FinBERT)\n",
      "API Key: 1246c60fda...\n",
      "Tickers: AAPL, MSFT, GOOGL\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2d5d7d064b4273b185dc15a342c663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a30b5756c9146a68136b600c711b605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: ProsusAI/finbert\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "✓ OPTIMIZATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Ticker   Sentiment    Weight     Return\n",
      "------------------------------------------------------------\n",
      "AAPL     +0.117          36.6%      12.9%\n",
      "MSFT     -0.280          34.5%      10.1%\n",
      "GOOGL    -0.044          28.9%      17.5%\n",
      "------------------------------------------------------------\n",
      "Portfolio Return:  13.3%\n",
      "Portfolio Vol:     15.2%\n",
      "Sharpe Ratio:      0.87\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPARISON VISUALIZATIONS...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PORTFOLIO COMPARISON VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE COMPARISON TABLE\n",
      "================================================================================\n",
      "\n",
      "Strategy             Return       Volatility   Sharpe    \n",
      "------------------------------------------------------------\n",
      "Market-Cap                13.50%       16.43%     0.822\n",
      "Mean-Variance             13.50%       16.43%     0.822\n",
      "Black-Litterman           13.26%       16.19%     0.819\n",
      "------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "1. MARKET-CAP WEIGHTED (Green - Benchmark):\n",
      "   - Equal weights: 33.3% each\n",
      "   - Return: 13.50%\n",
      "   - Sharpe: 0.822\n",
      "   → Simple, transparent baseline\n",
      "\n",
      "2. MEAN-VARIANCE (Orange - Often Unstable):\n",
      "   - Max concentration: 33.3%\n",
      "   - Return: 13.50%\n",
      "   - Sharpe: 0.822\n",
      "   → Sensitive to estimation errors\n",
      "\n",
      "3. BLACK-LITTERMAN (Red - Sentiment-Enhanced):\n",
      "   - Max concentration: 36.6%\n",
      "   - Return: 13.26%\n",
      "   - Sharpe: 0.819\n",
      "   ✓ Stable, incorporates sentiment views\n",
      "\n",
      "✨ Sharpe Improvement vs Benchmark: -0.3%\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"42e262eb-98ea-4e3f-ac46-824b8452cc3d\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"42e262eb-98ea-4e3f-ac46-824b8452cc3d\")) {                    Plotly.newPlot(                        \"42e262eb-98ea-4e3f-ac46-824b8452cc3d\",                        [{\"hovertemplate\":\"Market-Cap\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.822\",\"marker\":{\"color\":\"green\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Market-Cap\",\"showlegend\":true,\"text\":[\"Market-Cap\"],\"textposition\":\"top center\",\"x\":[16.431627128301248],\"y\":[13.499918504176279],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"Mean-Variance\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.822\",\"marker\":{\"color\":\"orange\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Mean-Variance\",\"showlegend\":true,\"text\":[\"Mean-Variance\"],\"textposition\":\"top center\",\"x\":[16.43162712830125],\"y\":[13.499918504176279],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"Black-Litterman\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.819\",\"marker\":{\"color\":\"red\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"star\"},\"mode\":\"markers+text\",\"name\":\"Black-Litterman\",\"showlegend\":true,\"text\":[\"Black-Litterman\"],\"textposition\":\"top center\",\"x\":[16.192075127967],\"y\":[13.262549714713618],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"green\"},\"name\":\"Market-Cap\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[33.33333333333333,33.33333333333333,33.33333333333333],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"orange\"},\"name\":\"Mean-Variance\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[33.33333333333333,33.333333333333336,33.333333333333336],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"red\"},\"name\":\"Black-Litterman\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[36.59400960899976,34.478458494940675,28.92753189605956],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[\"green\",\"orange\",\"red\"]},\"showlegend\":false,\"text\":[\"13.5%\",\"13.5%\",\"13.3%\"],\"textposition\":\"outside\",\"x\":[\"Market-Cap\",\"Mean-Variance\",\"Black-Litterman\"],\"y\":[13.499918504176279,13.499918504176279,13.262549714713618],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[\"green\",\"orange\",\"red\"]},\"showlegend\":false,\"text\":[\"0.822\",\"0.822\",\"0.819\"],\"textposition\":\"outside\",\"x\":[\"Market-Cap\",\"Mean-Variance\",\"Black-Litterman\"],\"y\":[0.8215813564150625,0.8215813564150624,0.8190765920920476],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.44],\"title\":{\"text\":\"Volatility (%)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Return (%)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.56,1.0],\"title\":{\"text\":\"Assets\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Weight (%)\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.44]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Expected Return (%)\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.56,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Sharpe Ratio\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Risk-Return Comparison\",\"x\":0.22,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Portfolio Weights\",\"x\":0.78,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Expected Returns\",\"x\":0.22,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Sharpe Ratios\",\"x\":0.78,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Portfolio Strategies Comparison Dashboard\"},\"legend\":{\"x\":0.02,\"y\":0.98,\"bgcolor\":\"rgba(255,255,255,0.9)\"},\"height\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('42e262eb-98ea-4e3f-ac46-824b8452cc3d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Interactive plot saved: portfolio_comparison_20260207_150753.html\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_31b3145e-2322-488c-877b-8cf18a07afaf\", \"portfolio_comparison_20260207_150753.html\", 4570253)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Downloading portfolio_comparison_20260207_150753.html...\n",
      "\n",
      "================================================================================\n",
      "DONE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPARISON VISUALIZATIONS...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PORTFOLIO COMPARISON VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE COMPARISON TABLE\n",
      "================================================================================\n",
      "\n",
      "Strategy             Return       Volatility   Sharpe    \n",
      "------------------------------------------------------------\n",
      "Market-Cap                13.50%       15.49%     0.872\n",
      "Mean-Variance             13.26%       15.17%     0.874\n",
      "Black-Litterman           13.26%       15.17%     0.874\n",
      "------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "1. MARKET-CAP WEIGHTED (Green - Benchmark):\n",
      "   - Equal weights: 33.3% each\n",
      "   - Return: 13.50%\n",
      "   - Sharpe: 0.872\n",
      "   → Simple, transparent baseline\n",
      "\n",
      "2. MEAN-VARIANCE (Orange - Often Unstable):\n",
      "   - Max concentration: 36.5%\n",
      "   - Return: 13.26%\n",
      "   - Sharpe: 0.874\n",
      "   → Sensitive to estimation errors\n",
      "\n",
      "3. BLACK-LITTERMAN (Red - Sentiment-Enhanced):\n",
      "   - Max concentration: 36.6%\n",
      "   - Return: 13.26%\n",
      "   - Sharpe: 0.874\n",
      "   ✓ Stable, incorporates sentiment views\n",
      "\n",
      "✨ Sharpe Improvement vs Benchmark: +0.3%\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"23437750-3f81-4bb1-8a15-5a0787c6d659\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"23437750-3f81-4bb1-8a15-5a0787c6d659\")) {                    Plotly.newPlot(                        \"23437750-3f81-4bb1-8a15-5a0787c6d659\",                        [{\"hovertemplate\":\"Market-Cap\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.872\",\"marker\":{\"color\":\"green\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Market-Cap\",\"showlegend\":true,\"text\":[\"Market-Cap\"],\"textposition\":\"top center\",\"x\":[15.487414370642291],\"y\":[13.499918504176279],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"Mean-Variance\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.874\",\"marker\":{\"color\":\"orange\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Mean-Variance\",\"showlegend\":true,\"text\":[\"Mean-Variance\"],\"textposition\":\"top center\",\"x\":[15.169721977122515],\"y\":[13.263500810711747],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"Black-Litterman\\u003cbr\\u003eVol: %{x:.2f}%\\u003cbr\\u003eReturn: %{y:.2f}%\\u003cbr\\u003eSharpe: 0.874\",\"marker\":{\"color\":\"red\",\"line\":{\"color\":\"white\",\"width\":2},\"size\":20,\"symbol\":\"star\"},\"mode\":\"markers+text\",\"name\":\"Black-Litterman\",\"showlegend\":true,\"text\":[\"Black-Litterman\"],\"textposition\":\"top center\",\"x\":[15.172069665581958],\"y\":[13.262549714713618],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"green\"},\"name\":\"Market-Cap\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[33.33333333333333,33.33333333333333,33.33333333333333],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"orange\"},\"name\":\"Mean-Variance\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[36.548355203570985,34.53513824368113,28.91650655274789],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"red\"},\"name\":\"Black-Litterman\",\"showlegend\":false,\"x\":[\"AAPL\",\"MSFT\",\"GOOGL\"],\"y\":[36.59400960899976,34.478458494940675,28.92753189605956],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[\"green\",\"orange\",\"red\"]},\"showlegend\":false,\"text\":[\"13.5%\",\"13.3%\",\"13.3%\"],\"textposition\":\"outside\",\"x\":[\"Market-Cap\",\"Mean-Variance\",\"Black-Litterman\"],\"y\":[13.499918504176279,13.263500810711747,13.262549714713618],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[\"green\",\"orange\",\"red\"]},\"showlegend\":false,\"text\":[\"0.872\",\"0.874\",\"0.874\"],\"textposition\":\"outside\",\"x\":[\"Market-Cap\",\"Mean-Variance\",\"Black-Litterman\"],\"y\":[0.8716702595474245,0.8743404019344887,0.8741424213731294],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.44],\"title\":{\"text\":\"Volatility (%)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Return (%)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.56,1.0],\"title\":{\"text\":\"Assets\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Weight (%)\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.44]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Expected Return (%)\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.56,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Sharpe Ratio\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Risk-Return Comparison\",\"x\":0.22,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Portfolio Weights\",\"x\":0.78,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Expected Returns\",\"x\":0.22,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Sharpe Ratios\",\"x\":0.78,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Portfolio Strategies Comparison Dashboard\"},\"legend\":{\"x\":0.02,\"y\":0.98,\"bgcolor\":\"rgba(255,255,255,0.9)\"},\"height\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('23437750-3f81-4bb1-8a15-5a0787c6d659');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Interactive plot saved: portfolio_comparison_20260207_150754.html\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_83bc826e-0998-4193-9d28-8e20e3278ab9\", \"portfolio_comparison_20260207_150754.html\", 4570256)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Downloading portfolio_comparison_20260207_150754.html...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "========================================================================================\n",
    "COMPLETE BLACK-LITTERMAN + FINBERT INTEGRATION - FINAL VERSION\n",
    "Single-File Google Colab Ready Implementation\n",
    "========================================================================================\n",
    "\n",
    "\n",
    "\n",
    "Features:\n",
    "- Complete Black-Litterman model (Meucci 2008)\n",
    "- FinBERT sentiment analysis integration\n",
    "- Live NewsAPI data fetching\n",
    "- ViewGenerator (sentiment → Q, Ω calibration)\n",
    "- Portfolio optimization\n",
    "- Results export to Excel\n",
    "- DEMO mode for testing without API\n",
    "\n",
    "========================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: IMPORTS & SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Check and install dependencies for Google Colab\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError:\n",
    "    print(\"Installing yfinance...\")\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yfinance\", \"-q\"])\n",
    "    import yfinance as yf\n",
    "\n",
    "try:\n",
    "    from newsapi import NewsApiClient\n",
    "except ImportError:\n",
    "    print(\"Installing newsapi-python...\")\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"newsapi-python\", \"-q\"])\n",
    "    from newsapi import NewsApiClient\n",
    "\n",
    "try:\n",
    "    from transformers import BertTokenizer, BertForSequenceClassification\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"Installing transformers and torch...\")\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"torch\", \"-q\"])\n",
    "    from transformers import BertTokenizer, BertForSequenceClassification\n",
    "    import torch\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: DATA STRUCTURES\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class SentimentData:\n",
    "    \"\"\"Container for sentiment analysis results.\"\"\"\n",
    "    ticker: str\n",
    "    sentiment_mean: float\n",
    "    sentiment_std: float\n",
    "    news_count: int\n",
    "    raw_scores: List[float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BlackLittermanView:\n",
    "    \"\"\"Black-Litterman view specification (P, Q, Ω).\"\"\"\n",
    "    P: np.ndarray\n",
    "    Q: np.ndarray\n",
    "    Omega: np.ndarray\n",
    "    metadata: Dict\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: BLACK-LITTERMAN MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class BlackLittermanModel:\n",
    "    \"\"\"Black-Litterman portfolio optimization (Meucci 2008).\"\"\"\n",
    "\n",
    "    def __init__(self, pi: np.ndarray, sigma: np.ndarray):\n",
    "        \"\"\"Initialize Black-Litterman model.\"\"\"\n",
    "        self.pi = np.asarray(pi).flatten()\n",
    "        self.sigma = np.asarray(sigma)\n",
    "\n",
    "        n_assets = len(self.pi)\n",
    "        if self.sigma.shape != (n_assets, n_assets):\n",
    "            raise ValueError(f\"Sigma shape mismatch\")\n",
    "\n",
    "        if not np.allclose(self.sigma, self.sigma.T):\n",
    "            self.sigma = (self.sigma + self.sigma.T) / 2\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_equilibrium_returns(w_eq: np.ndarray, sigma: np.ndarray,\n",
    "                                    risk_aversion: float = 2.5) -> np.ndarray:\n",
    "        \"\"\"Compute equilibrium returns: π = 2λΣw_eq\"\"\"\n",
    "        return 2 * risk_aversion * sigma @ np.asarray(w_eq).flatten()\n",
    "\n",
    "    def compute_posterior(self, P: np.ndarray, Q: np.ndarray,\n",
    "                         Omega: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute Black-Litterman posterior (Meucci 2008, Eq 32-33).\n",
    "\n",
    "        μ_BL = π + ΣP'(PΣP' + Ω)^(-1)(Q - Pπ)\n",
    "        Σ_BL = Σ - ΣP'(PΣP' + Ω)^(-1)PΣ\n",
    "        \"\"\"\n",
    "        P = np.asarray(P)\n",
    "        Q = np.asarray(Q).flatten()\n",
    "        Omega = np.asarray(Omega)\n",
    "\n",
    "        K, N = P.shape\n",
    "        if Omega.ndim == 0 and K == 1:\n",
    "            Omega = Omega.reshape((1, 1))\n",
    "\n",
    "        # M = PΣP' + Ω\n",
    "        M = P @ self.sigma @ P.T + Omega\n",
    "\n",
    "        # Stable inversion\n",
    "        try:\n",
    "            M_inv = np.linalg.inv(M)\n",
    "        except:\n",
    "            M_inv = np.linalg.pinv(M)\n",
    "\n",
    "        # Posterior mean\n",
    "        mu_bl = self.pi + self.sigma @ P.T @ M_inv @ (Q - P @ self.pi)\n",
    "\n",
    "        # Posterior covariance\n",
    "        sigma_bl = self.sigma - self.sigma @ P.T @ M_inv @ P @ self.sigma\n",
    "\n",
    "        return mu_bl, sigma_bl\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: VIEW GENERATOR\n",
    "# ============================================================================\n",
    "\n",
    "class ViewGenerator:\n",
    "    \"\"\"Generate Black-Litterman views from FinBERT sentiment.\"\"\"\n",
    "\n",
    "    def __init__(self, tickers: List[str], volatilities: np.ndarray,\n",
    "                 sentiment_scaling: float = 0.02,\n",
    "                 base_uncertainty: float = 0.0001,\n",
    "                 news_volume_weight: float = 0.5,\n",
    "                 consistency_weight: float = 0.5,\n",
    "                 min_news_count: int = 3):\n",
    "        \"\"\"Initialize ViewGenerator.\"\"\"\n",
    "        self.tickers = tickers\n",
    "        self.volatilities = np.asarray(volatilities)\n",
    "        self.N = len(tickers)\n",
    "        self.sentiment_scaling = sentiment_scaling\n",
    "        self.base_uncertainty = base_uncertainty\n",
    "        self.news_volume_weight = news_volume_weight\n",
    "        self.consistency_weight = consistency_weight\n",
    "        self.min_news_count = min_news_count\n",
    "        self.ticker_to_idx = {t: i for i, t in enumerate(tickers)}\n",
    "\n",
    "    def generate_views(self, sentiment_data: Dict[str, SentimentData],\n",
    "                      prior_returns: np.ndarray,\n",
    "                      filter_weak_signals: bool = True,\n",
    "                      min_abs_sentiment: float = 0.1) -> BlackLittermanView:\n",
    "        \"\"\"Generate Black-Litterman views from sentiment data.\"\"\"\n",
    "\n",
    "        # Filter valid views\n",
    "        valid_views = []\n",
    "        for ticker, data in sentiment_data.items():\n",
    "            if ticker not in self.ticker_to_idx:\n",
    "                continue\n",
    "            if data.news_count < self.min_news_count:\n",
    "                continue\n",
    "            if filter_weak_signals and abs(data.sentiment_mean) < min_abs_sentiment:\n",
    "                continue\n",
    "            valid_views.append(data)\n",
    "\n",
    "        if not valid_views:\n",
    "            # Null view\n",
    "            P = np.zeros((1, self.N))\n",
    "            P[0, 0] = 1.0\n",
    "            Q = np.zeros(1)\n",
    "            Omega = np.eye(1) * 1e10\n",
    "            metadata = {'null_view': True, 'tickers': []}\n",
    "            return BlackLittermanView(P, Q, Omega, metadata)\n",
    "\n",
    "        K = len(valid_views)\n",
    "\n",
    "        # Build P\n",
    "        P = np.zeros((K, self.N))\n",
    "        for k, view_data in enumerate(valid_views):\n",
    "            asset_idx = self.ticker_to_idx[view_data.ticker]\n",
    "            P[k, asset_idx] = 1.0\n",
    "\n",
    "        # Compute Q: Q = π + sentiment × σ × scaling\n",
    "        Q = np.zeros(K)\n",
    "        for k, view_data in enumerate(valid_views):\n",
    "            asset_idx = self.ticker_to_idx[view_data.ticker]\n",
    "            base_return = prior_returns[asset_idx]\n",
    "            sentiment_impact = (view_data.sentiment_mean *\n",
    "                              self.volatilities[asset_idx] *\n",
    "                              self.sentiment_scaling)\n",
    "            Q[k] = base_return + sentiment_impact\n",
    "\n",
    "        # Compute Ω\n",
    "        Omega = np.zeros((K, K))\n",
    "        for k, view_data in enumerate(valid_views):\n",
    "            volume_unc = 1.0 / np.sqrt(max(view_data.news_count, 1))\n",
    "            consistency_unc = view_data.sentiment_std ** 2\n",
    "            Omega[k, k] = (self.base_uncertainty +\n",
    "                          self.news_volume_weight * volume_unc +\n",
    "                          self.consistency_weight * consistency_unc)\n",
    "\n",
    "        metadata = {\n",
    "            'tickers': [v.ticker for v in valid_views],\n",
    "            'sentiments': [v.sentiment_mean for v in valid_views],\n",
    "            'news_counts': [v.news_count for v in valid_views]\n",
    "        }\n",
    "\n",
    "        return BlackLittermanView(P, Q, Omega, metadata)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: FINBERT ANALYZER\n",
    "# ============================================================================\n",
    "\n",
    "class FinBERTAnalyzer:\n",
    "    \"\"\"FinBERT sentiment analysis.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Load FinBERT model.\"\"\"\n",
    "        logger.info(\"Loading FinBERT model...\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.model.eval()\n",
    "        logger.info(\"✓ FinBERT loaded\")\n",
    "\n",
    "    def analyze_sentiment(self, texts: List[str]) -> Tuple[np.ndarray, float, float]:\n",
    "        \"\"\"Analyze sentiment: Score = P(Pos) - P(Neg)\"\"\"\n",
    "        if not texts:\n",
    "            return np.array([]), 0.0, 0.5\n",
    "\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True,\n",
    "                               max_length=512, return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()\n",
    "        scores = probs[:, 0] - probs[:, 1]  # P(Pos) - P(Neg)\n",
    "\n",
    "        return probs, float(np.mean(scores)), float(np.std(scores)) if len(scores) > 1 else 0.5\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: MAIN OPTIMIZER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class SentimentBlackLittermanOptimizer:\n",
    "    \"\"\"Complete integration: NewsAPI → FinBERT → Black-Litterman\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, tickers: List[str],\n",
    "                 lookback_days: int = 252,\n",
    "                 news_lookback_days: int = 7,\n",
    "                 articles_per_ticker: int = 10,\n",
    "                 risk_aversion: float = 2.5,\n",
    "                 sentiment_scaling: float = 0.02):\n",
    "        \"\"\"Initialize optimizer.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.tickers = tickers\n",
    "        self.N = len(tickers)\n",
    "        self.lookback_days = lookback_days\n",
    "        self.news_lookback_days = news_lookback_days\n",
    "        self.articles_per_ticker = articles_per_ticker\n",
    "        self.risk_aversion = risk_aversion\n",
    "        self.sentiment_scaling = sentiment_scaling\n",
    "\n",
    "        self.newsapi = NewsApiClient(api_key=api_key)\n",
    "        self.finbert = FinBERTAnalyzer()\n",
    "\n",
    "        self.sigma = None\n",
    "        self.volatilities = None\n",
    "        self.pi = None\n",
    "        self.w_eq = None\n",
    "        self.bl_model = None\n",
    "        self.view_generator = None\n",
    "\n",
    "    def fetch_news(self, ticker: str) -> List[Dict]:\n",
    "        \"\"\"Fetch news for ticker.\"\"\"\n",
    "        try:\n",
    "            to_date = datetime.now()\n",
    "            from_date = to_date - timedelta(days=self.news_lookback_days)\n",
    "\n",
    "            response = self.newsapi.get_everything(\n",
    "                q=ticker,\n",
    "                language='en',\n",
    "                sort_by='relevancy',\n",
    "                page_size=self.articles_per_ticker,\n",
    "                from_param=from_date.strftime('%Y-%m-%d'),\n",
    "                to=to_date.strftime('%Y-%m-%d')\n",
    "            )\n",
    "\n",
    "            articles = response.get('articles', [])\n",
    "            logger.info(f\"  ✓ {ticker}: {len(articles)} articles\")\n",
    "            return articles\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  ✗ {ticker}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def process_ticker(self, ticker: str) -> Optional[SentimentData]:\n",
    "        \"\"\"Fetch news and analyze sentiment.\"\"\"\n",
    "        logger.info(f\"\\nProcessing {ticker}:\")\n",
    "\n",
    "        articles = self.fetch_news(ticker)\n",
    "        if not articles:\n",
    "            return None\n",
    "\n",
    "        texts = []\n",
    "        for article in articles:\n",
    "            title = article.get('title', '')\n",
    "            desc = article.get('description', '')\n",
    "            text = f\"{title}. {desc}\" if desc else title\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "\n",
    "        if not texts:\n",
    "            return None\n",
    "\n",
    "        probs, sentiment_mean, sentiment_std = self.finbert.analyze_sentiment(texts)\n",
    "\n",
    "        logger.info(f\"  Sentiment: {sentiment_mean:+.3f} (std: {sentiment_std:.3f})\")\n",
    "        logger.info(f\"  Sample: {texts[0][:60]}...\")\n",
    "\n",
    "        return SentimentData(\n",
    "            ticker=ticker,\n",
    "            sentiment_mean=sentiment_mean,\n",
    "            sentiment_std=sentiment_std,\n",
    "            news_count=len(texts),\n",
    "            raw_scores=(probs[:, 0] - probs[:, 1]).tolist()\n",
    "        )\n",
    "\n",
    "    def load_market_data(self):\n",
    "        \"\"\"Load historical data - FIXED VERSION.\"\"\"\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"LOADING MARKET DATA\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=self.lookback_days + 30)\n",
    "\n",
    "        # Download all tickers at once (more efficient)\n",
    "        logger.info(f\"Downloading data for {len(self.tickers)} tickers...\")\n",
    "\n",
    "        try:\n",
    "            # Download all at once\n",
    "            data = yf.download(self.tickers, start=start_date, end=end_date,\n",
    "                             group_by='ticker', progress=False, threads=True)\n",
    "\n",
    "            # Extract Close prices\n",
    "            prices_dict = {}\n",
    "            for ticker in self.tickers:\n",
    "                try:\n",
    "                    if len(self.tickers) == 1:\n",
    "                        # Single ticker case\n",
    "                        prices_dict[ticker] = data['Close']\n",
    "                    else:\n",
    "                        # Multiple tickers\n",
    "                        prices_dict[ticker] = data[ticker]['Close']\n",
    "\n",
    "                    logger.info(f\"  ✓ {ticker}: {len(prices_dict[ticker])} days\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"  ⚠ {ticker}: {e}\")\n",
    "\n",
    "            if not prices_dict:\n",
    "                raise ValueError(\"No data loaded for any ticker!\")\n",
    "\n",
    "            # Create DataFrame and align\n",
    "            prices_df = pd.DataFrame(prices_dict)\n",
    "            prices_df = prices_df.dropna()\n",
    "\n",
    "            if len(prices_df) < 50:\n",
    "                raise ValueError(f\"Insufficient data: only {len(prices_df)} days\")\n",
    "\n",
    "            logger.info(f\"\\nCommon trading days: {len(prices_df)}\")\n",
    "\n",
    "            # Compute returns\n",
    "            returns_df = np.log(prices_df / prices_df.shift(1)).dropna()\n",
    "\n",
    "            # Estimate covariance\n",
    "            self.sigma = returns_df.cov().values * 252\n",
    "            self.sigma += np.eye(self.N) * 1e-6\n",
    "\n",
    "            # Volatilities\n",
    "            self.volatilities = np.sqrt(np.diag(self.sigma))\n",
    "\n",
    "            logger.info(\"\\nVolatilities (annualized):\")\n",
    "            for i, ticker in enumerate(self.tickers):\n",
    "                logger.info(f\"  {ticker}: {self.volatilities[i]*100:5.1f}%\")\n",
    "\n",
    "            # Equilibrium\n",
    "            self.w_eq = np.ones(self.N) / self.N\n",
    "            self.pi = BlackLittermanModel.compute_equilibrium_returns(\n",
    "                self.w_eq, self.sigma, self.risk_aversion\n",
    "            )\n",
    "\n",
    "            logger.info(\"\\nEquilibrium Returns:\")\n",
    "            for i, ticker in enumerate(self.tickers):\n",
    "                logger.info(f\"  {ticker}: {self.pi[i]*100:5.1f}%\")\n",
    "\n",
    "            # Initialize models\n",
    "            self.bl_model = BlackLittermanModel(self.pi, self.sigma)\n",
    "            self.view_generator = ViewGenerator(\n",
    "                tickers=self.tickers,\n",
    "                volatilities=self.volatilities,\n",
    "                sentiment_scaling=self.sentiment_scaling\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading market data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def optimize(self) -> Optional[Dict]:\n",
    "        \"\"\"Run complete optimization.\"\"\"\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"SENTIMENT BLACK-LITTERMAN OPTIMIZATION\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        # Load market data\n",
    "        if self.sigma is None:\n",
    "            self.load_market_data()\n",
    "\n",
    "        # Fetch news & analyze\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"FETCHING NEWS & ANALYZING SENTIMENT\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        sentiment_data = {}\n",
    "        for ticker in self.tickers:\n",
    "            data = self.process_ticker(ticker)\n",
    "            if data:\n",
    "                sentiment_data[ticker] = data\n",
    "\n",
    "        if not sentiment_data:\n",
    "            logger.error(\"\\n✗ No valid sentiment data\")\n",
    "            return None\n",
    "\n",
    "        # Generate views\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"GENERATING VIEWS\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        view = self.view_generator.generate_views(\n",
    "            sentiment_data, self.pi,\n",
    "            filter_weak_signals=True, min_abs_sentiment=0.10\n",
    "        )\n",
    "\n",
    "        logger.info(f\"\\n✓ Generated {view.P.shape[0]} views\")\n",
    "        logger.info(f\"  Tickers: {view.metadata.get('tickers', [])}\")\n",
    "\n",
    "        # Black-Litterman\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"BLACK-LITTERMAN POSTERIOR\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        mu_bl, sigma_bl = self.bl_model.compute_posterior(view.P, view.Q, view.Omega)\n",
    "\n",
    "        logger.info(\"\\nPosterior Returns:\")\n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            delta = mu_bl[i] - self.pi[i]\n",
    "            direction = \"↑\" if delta > 0 else \"↓\" if delta < 0 else \"→\"\n",
    "            logger.info(f\"  {ticker}: {self.pi[i]*100:5.1f}% → {mu_bl[i]*100:5.1f}% \"\n",
    "                       f\"{direction} ({delta*100:+.1f}%)\")\n",
    "\n",
    "        # Optimize\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"PORTFOLIO OPTIMIZATION\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "\n",
    "        try:\n",
    "            sigma_inv = np.linalg.inv(sigma_bl)\n",
    "        except:\n",
    "            sigma_inv = np.linalg.pinv(sigma_bl)\n",
    "\n",
    "        w_optimal = sigma_inv @ mu_bl / (2 * self.risk_aversion)\n",
    "        w_optimal = np.maximum(w_optimal, 0)\n",
    "        w_optimal = w_optimal / np.sum(w_optimal)\n",
    "\n",
    "        logger.info(\"\\nOptimal Weights:\")\n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            logger.info(f\"  {ticker}: {w_optimal[i]*100:5.1f}%\")\n",
    "\n",
    "        portfolio_return = w_optimal @ mu_bl\n",
    "        portfolio_vol = np.sqrt(w_optimal @ sigma_bl @ w_optimal)\n",
    "        sharpe = portfolio_return / portfolio_vol if portfolio_vol > 0 else 0\n",
    "\n",
    "        logger.info(f\"\\nPortfolio:\")\n",
    "        logger.info(f\"  Return: {portfolio_return*100:5.1f}%\")\n",
    "        logger.info(f\"  Vol:    {portfolio_vol*100:5.1f}%\")\n",
    "        logger.info(f\"  Sharpe: {sharpe:.2f}\")\n",
    "\n",
    "        return {\n",
    "            'timestamp': datetime.now(),\n",
    "            'tickers': self.tickers,\n",
    "            'sentiment_data': sentiment_data,\n",
    "            'view': view,\n",
    "            'prior_returns': self.pi,\n",
    "            'posterior_returns': mu_bl,\n",
    "            'prior_weights': self.w_eq,\n",
    "            'optimal_weights': w_optimal,\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'portfolio_vol': portfolio_vol,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'sigma': self.sigma,  # Add original covariance\n",
    "            'sigma_bl': sigma_bl  # Add posterior covariance\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: DEMO MODE\n",
    "# ============================================================================\n",
    "\n",
    "def run_demo_mode(tickers: List[str] = None):\n",
    "    \"\"\"Demo mode with simulated sentiment (no API needed).\"\"\"\n",
    "    if tickers is None:\n",
    "        tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DEMO MODE - SIMULATED SENTIMENT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Load market data\n",
    "    print(\"\\nLoading market data...\")\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=282)\n",
    "\n",
    "    try:\n",
    "        data = yf.download(tickers, start=start_date, end=end_date,\n",
    "                          group_by='ticker', progress=False)\n",
    "\n",
    "        prices_dict = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                if len(tickers) == 1:\n",
    "                    prices_dict[ticker] = data['Close']\n",
    "                else:\n",
    "                    prices_dict[ticker] = data[ticker]['Close']\n",
    "                print(f\"  ✓ {ticker}: {len(prices_dict[ticker])} days\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        prices_df = pd.DataFrame(prices_dict).dropna()\n",
    "        returns_df = np.log(prices_df / prices_df.shift(1)).dropna()\n",
    "\n",
    "        N = len(tickers)\n",
    "        sigma = returns_df.cov().values * 252\n",
    "        sigma += np.eye(N) * 1e-6\n",
    "        volatilities = np.sqrt(np.diag(sigma))\n",
    "\n",
    "        w_eq = np.ones(N) / N\n",
    "        pi = BlackLittermanModel.compute_equilibrium_returns(w_eq, sigma, 2.5)\n",
    "\n",
    "        print(\"\\nEquilibrium Returns:\")\n",
    "        for i, ticker in enumerate(tickers):\n",
    "            print(f\"  {ticker}: {pi[i]*100:5.1f}%\")\n",
    "\n",
    "        # Simulated sentiment\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SIMULATED SENTIMENT\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        sentiment_data = {}\n",
    "\n",
    "        base_sentiments = {'AAPL': 0.45, 'MSFT': 0.35, 'GOOGL': 0.25,\n",
    "                          'TSLA': -0.20, 'NVDA': 0.60}\n",
    "\n",
    "        for ticker in tickers:\n",
    "            base = base_sentiments.get(ticker, np.random.uniform(-0.3, 0.3))\n",
    "            news_count = np.random.randint(8, 25)\n",
    "            raw_scores = np.clip(np.random.normal(base, 0.2, news_count), -1, 1)\n",
    "\n",
    "            sentiment_data[ticker] = SentimentData(\n",
    "                ticker=ticker,\n",
    "                sentiment_mean=float(np.mean(raw_scores)),\n",
    "                sentiment_std=float(np.std(raw_scores)),\n",
    "                news_count=news_count,\n",
    "                raw_scores=raw_scores.tolist()\n",
    "            )\n",
    "\n",
    "            print(f\"  {ticker}: {sentiment_data[ticker].sentiment_mean:+.3f} \"\n",
    "                  f\"({news_count} articles)\")\n",
    "\n",
    "        # Generate views\n",
    "        generator = ViewGenerator(tickers, volatilities, 0.02)\n",
    "        view = generator.generate_views(sentiment_data, pi, True, 0.10)\n",
    "\n",
    "        print(f\"\\n✓ Generated {view.P.shape[0]} views\")\n",
    "\n",
    "        # Black-Litterman\n",
    "        bl = BlackLittermanModel(pi, sigma)\n",
    "        mu_bl, sigma_bl = bl.compute_posterior(view.P, view.Q, view.Omega)\n",
    "\n",
    "        # Optimize\n",
    "        sigma_inv = np.linalg.pinv(sigma_bl)\n",
    "        w_optimal = sigma_inv @ mu_bl / 5.0\n",
    "        w_optimal = np.maximum(w_optimal, 0)\n",
    "        w_optimal = w_optimal / np.sum(w_optimal)\n",
    "\n",
    "        # Results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL PORTFOLIO\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\n{'Ticker':<8} {'Sentiment':<12} {'Weight':<10} {'Return'}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        for i, ticker in enumerate(tickers):\n",
    "            sent = sentiment_data[ticker].sentiment_mean\n",
    "            print(f\"{ticker:<8} {sent:>+.3f}         {w_optimal[i]*100:>5.1f}%     \"\n",
    "                  f\"{mu_bl[i]*100:>5.1f}%\")\n",
    "\n",
    "        portfolio_return = w_optimal @ mu_bl\n",
    "        portfolio_vol = np.sqrt(w_optimal @ sigma_bl @ w_optimal)\n",
    "        sharpe = portfolio_return / portfolio_vol if portfolio_vol > 0 else 0\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Portfolio Return: {portfolio_return*100:>5.1f}%\")\n",
    "        print(f\"Portfolio Vol:    {portfolio_vol*100:>5.1f}%\")\n",
    "        print(f\"Sharpe Ratio:     {sharpe:>5.2f}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        results = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'tickers': tickers,\n",
    "            'sentiment_data': sentiment_data,\n",
    "            'view': view,\n",
    "            'prior_returns': pi,\n",
    "            'posterior_returns': mu_bl,\n",
    "            'prior_weights': w_eq,\n",
    "            'optimal_weights': w_optimal,\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'portfolio_vol': portfolio_vol,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'sigma': sigma,\n",
    "            'sigma_bl': sigma_bl\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 8: MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Google Colab Execution\n",
    "\n",
    "    Two modes:\n",
    "    1. DEMO MODE (simulated sentiment) - No API key needed\n",
    "    2. LIVE MODE (real news) - Uses NewsAPI\n",
    "    \"\"\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # CONFIGURATION\n",
    "    # ========================================================================\n",
    "\n",
    "    USE_DEMO_MODE = False  # Set to True for demo, False for live\n",
    "\n",
    "    # YOUR REAL API KEY\n",
    "    NEWS_API_KEY = \"1246c60fdabd4db7b6d55b5fcfa73c14\"\n",
    "\n",
    "    # Portfolio\n",
    "    TICKERS = ['AAPL', 'MSFT', 'GOOGL']  # Start with 3 for testing\n",
    "\n",
    "    # Parameters\n",
    "    LOOKBACK_DAYS = 252\n",
    "    NEWS_LOOKBACK_DAYS = 7\n",
    "    RISK_AVERSION = 2.5\n",
    "\n",
    "    # ========================================================================\n",
    "    # RUN\n",
    "    # ========================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BLACK-LITTERMAN + FINBERT PORTFOLIO OPTIMIZATION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if USE_DEMO_MODE:\n",
    "        print(\"\\nMode: DEMO (simulated sentiment)\")\n",
    "        print(\"Set USE_DEMO_MODE = False for live news\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        results = run_demo_mode(TICKERS)\n",
    "\n",
    "        # Create comparison visualization\n",
    "        if results is not None:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"CREATING COMPARISON VISUALIZATIONS...\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "            viz_results = create_portfolio_comparison_plots(\n",
    "                tickers=TICKERS,\n",
    "                results=results,\n",
    "                show_plots=True\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(\"\\nMode: LIVE (real NewsAPI + FinBERT)\")\n",
    "        print(f\"API Key: {NEWS_API_KEY[:10]}...\")\n",
    "        print(f\"Tickers: {', '.join(TICKERS)}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        try:\n",
    "            optimizer = SentimentBlackLittermanOptimizer(\n",
    "                api_key=NEWS_API_KEY,\n",
    "                tickers=TICKERS,\n",
    "                lookback_days=LOOKBACK_DAYS,\n",
    "                news_lookback_days=NEWS_LOOKBACK_DAYS,\n",
    "                risk_aversion=RISK_AVERSION\n",
    "            )\n",
    "\n",
    "            results = optimizer.optimize()\n",
    "\n",
    "            if results:\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"✓ OPTIMIZATION COMPLETE\")\n",
    "                print(\"=\"*80)\n",
    "\n",
    "                print(f\"\\n{'Ticker':<8} {'Sentiment':<12} {'Weight':<10} {'Return'}\")\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "                for i, ticker in enumerate(TICKERS):\n",
    "                    sent_data = results['sentiment_data'].get(ticker)\n",
    "                    sent = sent_data.sentiment_mean if sent_data else 0.0\n",
    "                    weight = results['optimal_weights'][i]\n",
    "                    ret = results['posterior_returns'][i]\n",
    "\n",
    "                    print(f\"{ticker:<8} {sent:>+.3f}         {weight*100:>5.1f}%     \"\n",
    "                          f\"{ret*100:>5.1f}%\")\n",
    "\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"Portfolio Return: {results['portfolio_return']*100:>5.1f}%\")\n",
    "                print(f\"Portfolio Vol:    {results['portfolio_vol']*100:>5.1f}%\")\n",
    "                print(f\"Sharpe Ratio:     {results['sharpe_ratio']:>5.2f}\")\n",
    "                print(\"=\"*80)\n",
    "\n",
    "                # Create comparison visualization\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"CREATING COMPARISON VISUALIZATIONS...\")\n",
    "                print(\"=\"*80)\n",
    "\n",
    "                viz_results = create_portfolio_comparison_plots(\n",
    "                    tickers=TICKERS,\n",
    "                    results=results,\n",
    "                    show_plots=True\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"✗ ERROR\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"\\nError: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"\\nTry setting USE_DEMO_MODE = True to test without API\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DONE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 9: PORTFOLIO COMPARISON VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_portfolio_comparison_plots(\n",
    "    tickers: List[str],\n",
    "    results: Dict,\n",
    "    show_plots: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Create comparison plots: Market-Cap vs Mean-Variance vs Black-Litterman.\n",
    "\n",
    "    Parameters:\n",
    "        tickers: List of tickers\n",
    "        results: Results from optimize()\n",
    "        show_plots: Display plots interactively\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of Plotly figures\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import plotly.graph_objects as go\n",
    "        from plotly.subplots import make_subplots\n",
    "    except ImportError:\n",
    "        print(\"Installing plotly...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"plotly\", \"-q\"])\n",
    "        import plotly.graph_objects as go\n",
    "        from plotly.subplots import make_subplots\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PORTFOLIO COMPARISON VISUALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Extract data from results\n",
    "    if results is None:\n",
    "        print(\"✗ No results to visualize\")\n",
    "        return None\n",
    "\n",
    "    mu_bl = results.get('posterior_returns')\n",
    "    sigma = results.get('sigma_bl')  # Use posterior covariance\n",
    "    w_eq = results.get('prior_weights')\n",
    "    w_bl = results.get('optimal_weights')\n",
    "\n",
    "    # If sigma_bl not available, recompute from prices\n",
    "    if sigma is None:\n",
    "        print(\"  Computing covariance from historical data...\")\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=282)\n",
    "\n",
    "        try:\n",
    "            data = yf.download(tickers, start=start_date, end=end_date,\n",
    "                             group_by='ticker', progress=False)\n",
    "\n",
    "            prices_dict = {}\n",
    "            for ticker in tickers:\n",
    "                try:\n",
    "                    if len(tickers) == 1:\n",
    "                        prices_dict[ticker] = data['Close']\n",
    "                    else:\n",
    "                        prices_dict[ticker] = data[ticker]['Close']\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            prices_df = pd.DataFrame(prices_dict).dropna()\n",
    "            returns_df = np.log(prices_df / prices_df.shift(1)).dropna()\n",
    "            sigma = returns_df.cov().values * 252\n",
    "            sigma += np.eye(len(tickers)) * 1e-6\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Could not compute covariance: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Validate dimensions\n",
    "    if sigma is None or sigma.ndim != 2:\n",
    "        print(\"✗ Invalid covariance matrix\")\n",
    "        return None\n",
    "\n",
    "    # Compute Mean-Variance (unstable)\n",
    "    mu_hist = results['prior_returns']  # Use prior as proxy for historical\n",
    "\n",
    "    try:\n",
    "        sigma_inv = np.linalg.inv(sigma)\n",
    "    except:\n",
    "        sigma_inv = np.linalg.pinv(sigma)\n",
    "\n",
    "    w_mv = sigma_inv @ mu_hist / 5.0\n",
    "    w_mv = np.maximum(w_mv, 0)\n",
    "    if np.sum(w_mv) > 0.01:\n",
    "        w_mv = w_mv / np.sum(w_mv)\n",
    "    else:\n",
    "        w_mv = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "    # Compute statistics\n",
    "    def portfolio_stats(w, mu, sigma):\n",
    "        ret = w @ mu\n",
    "        vol = np.sqrt(w @ sigma @ w)\n",
    "        sharpe = ret / vol if vol > 0 else 0\n",
    "        return ret, vol, sharpe\n",
    "\n",
    "    stats_eq = portfolio_stats(w_eq, mu_hist, sigma)\n",
    "    stats_mv = portfolio_stats(w_mv, mu_hist, sigma)\n",
    "    stats_bl = portfolio_stats(w_bl, mu_bl, sigma)\n",
    "\n",
    "    # ========================================================================\n",
    "    # PLOT 1: Comprehensive Dashboard\n",
    "    # ========================================================================\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Risk-Return Comparison',\n",
    "            'Portfolio Weights',\n",
    "            'Expected Returns',\n",
    "            'Sharpe Ratios'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'bar'}]\n",
    "        ],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.12\n",
    "    )\n",
    "\n",
    "    # 1. Risk-Return Scatter\n",
    "    strategies = [\n",
    "        ('Market-Cap', stats_eq, 'green', 'circle'),\n",
    "        ('Mean-Variance', stats_mv, 'orange', 'square'),\n",
    "        ('Black-Litterman', stats_bl, 'red', 'star')\n",
    "    ]\n",
    "\n",
    "    for name, (ret, vol, sharpe), color, symbol in strategies:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[vol * 100],\n",
    "                y=[ret * 100],\n",
    "                mode='markers+text',\n",
    "                name=name,\n",
    "                marker=dict(size=20, color=color, symbol=symbol,\n",
    "                          line=dict(width=2, color='white')),\n",
    "                text=[name],\n",
    "                textposition='top center',\n",
    "                hovertemplate=f'{name}<br>Vol: %{{x:.2f}}%<br>Return: %{{y:.2f}}%<br>Sharpe: {sharpe:.3f}',\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # 2. Weights Comparison\n",
    "    weights_data = [\n",
    "        ('Market-Cap', w_eq, 'green'),\n",
    "        ('Mean-Variance', w_mv, 'orange'),\n",
    "        ('Black-Litterman', w_bl, 'red')\n",
    "    ]\n",
    "\n",
    "    for name, weights, color in weights_data:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=tickers,\n",
    "                y=weights * 100,\n",
    "                name=name,\n",
    "                marker_color=color,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "    # 3. Expected Returns\n",
    "    returns_data = [stats_eq[0] * 100, stats_mv[0] * 100, stats_bl[0] * 100]\n",
    "    names = ['Market-Cap', 'Mean-Variance', 'Black-Litterman']\n",
    "    colors = ['green', 'orange', 'red']\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=names,\n",
    "            y=returns_data,\n",
    "            marker_color=colors,\n",
    "            showlegend=False,\n",
    "            text=[f'{r:.1f}%' for r in returns_data],\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # 4. Sharpe Ratios\n",
    "    sharpe_data = [stats_eq[2], stats_mv[2], stats_bl[2]]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=names,\n",
    "            y=sharpe_data,\n",
    "            marker_color=colors,\n",
    "            showlegend=False,\n",
    "            text=[f'{s:.3f}' for s in sharpe_data],\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text='Volatility (%)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Return (%)', row=1, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text='Assets', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Weight (%)', row=1, col=2)\n",
    "\n",
    "    fig.update_yaxes(title_text='Expected Return (%)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Sharpe Ratio', row=2, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text='Portfolio Strategies Comparison Dashboard',\n",
    "        template='plotly_white',\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0.02, y=0.98, bgcolor='rgba(255,255,255,0.9)')\n",
    "    )\n",
    "\n",
    "    # Print comparison table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PERFORMANCE COMPARISON TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n{'Strategy':<20} {'Return':<12} {'Volatility':<12} {'Sharpe':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for name, (ret, vol, sharpe), _, _ in strategies:\n",
    "        print(f\"{name:<20} {ret*100:>10.2f}%  {vol*100:>10.2f}%  {sharpe:>8.3f}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Key insights\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY INSIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"\\n1. MARKET-CAP WEIGHTED (Green - Benchmark):\")\n",
    "    print(f\"   - Equal weights: {w_eq[0]*100:.1f}% each\")\n",
    "    print(f\"   - Return: {stats_eq[0]*100:.2f}%\")\n",
    "    print(f\"   - Sharpe: {stats_eq[2]:.3f}\")\n",
    "    print(\"   → Simple, transparent baseline\")\n",
    "\n",
    "    print(\"\\n2. MEAN-VARIANCE (Orange - Often Unstable):\")\n",
    "    concentration_mv = np.max(w_mv) * 100\n",
    "    print(f\"   - Max concentration: {concentration_mv:.1f}%\")\n",
    "    print(f\"   - Return: {stats_mv[0]*100:.2f}%\")\n",
    "    print(f\"   - Sharpe: {stats_mv[2]:.3f}\")\n",
    "    if concentration_mv > 60:\n",
    "        print(\"   ⚠ HIGH CONCENTRATION - Sign of instability!\")\n",
    "    print(\"   → Sensitive to estimation errors\")\n",
    "\n",
    "    print(\"\\n3. BLACK-LITTERMAN (Red - Sentiment-Enhanced):\")\n",
    "    concentration_bl = np.max(w_bl) * 100\n",
    "    print(f\"   - Max concentration: {concentration_bl:.1f}%\")\n",
    "    print(f\"   - Return: {stats_bl[0]*100:.2f}%\")\n",
    "    print(f\"   - Sharpe: {stats_bl[2]:.3f}\")\n",
    "    print(\"   ✓ Stable, incorporates sentiment views\")\n",
    "\n",
    "    # Improvement metrics\n",
    "    sharpe_improvement = ((stats_bl[2] - stats_eq[2]) / stats_eq[2]) * 100\n",
    "    print(f\"\\n✨ Sharpe Improvement vs Benchmark: {sharpe_improvement:+.1f}%\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Show plot\n",
    "    if show_plots:\n",
    "        fig.show()\n",
    "\n",
    "    # Save HTML\n",
    "    try:\n",
    "        filename = f\"portfolio_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        fig.write_html(filename)\n",
    "        print(f\"\\n✓ Interactive plot saved: {filename}\")\n",
    "\n",
    "        # Download in Colab\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(filename)\n",
    "            print(f\"✓ Downloading {filename}...\")\n",
    "        except:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠ Could not save HTML: {e}\")\n",
    "\n",
    "    return {\n",
    "        'figure': fig,\n",
    "        'stats': {\n",
    "            'market_cap': stats_eq,\n",
    "            'mean_variance': stats_mv,\n",
    "            'black_litterman': stats_bl\n",
    "        },\n",
    "        'weights': {\n",
    "            'market_cap': w_eq,\n",
    "            'mean_variance': w_mv,\n",
    "            'black_litterman': w_bl\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Add to main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # ... existing code ...\n",
    "\n",
    "    # After optimization completes, add visualization\n",
    "    if not USE_DEMO_MODE and results is not None:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CREATING COMPARISON VISUALIZATIONS...\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        viz_results = create_portfolio_comparison_plots(\n",
    "            tickers=TICKERS,\n",
    "            results=results,\n",
    "            show_plots=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Taj-GZaDLDl"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}